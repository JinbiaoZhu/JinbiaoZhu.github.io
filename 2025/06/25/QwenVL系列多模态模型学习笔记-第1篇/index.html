

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Jinbiao Zhu">
  <meta name="keywords" content="">
  
    <meta name="description" content="第一代 Qwen-VL 2023.08-2023.10当时大多数的 LVLMs 都是以粗粒度的方式感知图像，缺乏图像细粒度感知的能力（包括目标定位和文本读取等）。基于当时的问题，Qwen 团队引入了一个新的视觉编码器和位置感知适配器，并且设计了一个三阶段训练的流程用于优化 Qwen-VL 模型。Qwen-VL 的特点：性能领先、支持多语言、支持任意交错的 “图像-文本” 数据、细粒度的视觉理解（例">
<meta property="og:type" content="article">
<meta property="og:title" content="QwenVL系列多模态模型学习笔记_第1篇">
<meta property="og:url" content="http://example.com/2025/06/25/QwenVL%E7%B3%BB%E5%88%97%E5%A4%9A%E6%A8%A1%E6%80%81%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%AC%AC1%E7%AF%87/index.html">
<meta property="og:site_name" content="JinbiaoZhu">
<meta property="og:description" content="第一代 Qwen-VL 2023.08-2023.10当时大多数的 LVLMs 都是以粗粒度的方式感知图像，缺乏图像细粒度感知的能力（包括目标定位和文本读取等）。基于当时的问题，Qwen 团队引入了一个新的视觉编码器和位置感知适配器，并且设计了一个三阶段训练的流程用于优化 Qwen-VL 模型。Qwen-VL 的特点：性能领先、支持多语言、支持任意交错的 “图像-文本” 数据、细粒度的视觉理解（例">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/2025/06/25/QwenVL%E7%B3%BB%E5%88%97%E5%A4%9A%E6%A8%A1%E6%80%81%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%AC%AC1%E7%AF%87/qwenvl_01.png">
<meta property="article:published_time" content="2025-06-25T08:02:32.000Z">
<meta property="article:modified_time" content="2025-06-25T14:41:00.910Z">
<meta property="article:author" content="Jinbiao Zhu">
<meta property="article:tag" content="多模态大模型">
<meta property="article:tag" content="Qwen-VL">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://example.com/2025/06/25/QwenVL%E7%B3%BB%E5%88%97%E5%A4%9A%E6%A8%A1%E6%80%81%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%AC%AC1%E7%AF%87/qwenvl_01.png">
  
  
  
  <title>QwenVL系列多模态模型学习笔记_第1篇 - JinbiaoZhu</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.8","typing":{"enable":false,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>JinbiaoZhu</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle">QwenVL系列多模态模型学习笔记_第1篇</span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-06-25 16:02" pubdate>
          2025年6月25日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          2.1k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          18 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">QwenVL系列多模态模型学习笔记_第1篇</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="第一代-Qwen-VL-2023-08-2023-10"><a href="#第一代-Qwen-VL-2023-08-2023-10" class="headerlink" title="第一代 Qwen-VL 2023.08-2023.10"></a>第一代 Qwen-VL 2023.08-2023.10</h1><p>当时大多数的 LVLMs 都是以<b>粗粒度</b>的方式感知图像，缺乏<u>图像细粒度感知</u>的能力（包括<b>目标定位</b>和<b>文本读取</b>等）。基于当时的问题，Qwen 团队引入了一个<u>新的视觉编码器</u>和<u>位置感知适配器</u>，并且设计了一个三阶段训练的流程用于优化 Qwen-VL 模型。Qwen-VL 的特点：性能领先、支持多语言、<strong>支持任意交错的 “图像-文本” 数据</strong>、<strong>细粒度的视觉理解</strong>（例如 OCR）。Qwen-VL 相较于之前的<b>图文多模态大模型</b>多了一个功能：视觉定位，就是可以<b>给出一个框</b>将你想要的地方框出来。</p>
<h2 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h2><p><img src="/2025/06/25/QwenVL%E7%B3%BB%E5%88%97%E5%A4%9A%E6%A8%A1%E6%80%81%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%AC%AC1%E7%AF%87/qwenvl_01.png" srcset="/img/loading.gif" lazyload></p>
<blockquote>
<p>通常一个多模态 “视觉—语言” 模型包含三个结构：语言模型、视觉编码器和 “视觉—语言” 适配器。</p>
</blockquote>
<p>Qwen-VL 整个模型参数大致在 1.9B + 0.08B + 7.7B &#x3D; 9.6B 的参数数量。</p>
<ol>
<li><p>语言模型：Qwen-7B 大语言模型；</p>
</li>
<li><p>视觉编码器：ViT 的架构，参数量在 1.9B ，并且从<a target="_blank" rel="noopener" href="https://github.com/mlfoundations/open_clip">开源项目 openclip 的 ViT-bigG</a> 权重开始初始化，训练和推理的过程中图像会被调整到特定的分辨率，也就是拆成 14x14 像素的 patch 块；</p>
</li>
<li><p>（位置级）视觉语言适配器：一个<u>随机权重初始化</u>的<u>单层交叉注意力模块</u>组成，参数量在 0.08B 。</p>
<p>该模块使用一组<b>可训练的向量（意思就是在训练中张量数值会改变，且梯度会流向这个向量）</b>作为 query 向量，将<b>视觉编码器的特征</b>作为 key 进行交叉注意力操作，将图像特征压缩到 256 长度的序列。并且将 2D 绝对位置编码用在交叉注意力机制中，以减轻压缩过程中的位置细节丢失。</p>
</li>
</ol>
<h2 id="模型输入和输出"><a href="#模型输入和输出" class="headerlink" title="模型输入和输出"></a>模型输入和输出</h2><p>图像输入：<code>&lt;img&gt;</code> 和 <code>&lt;/img&gt;</code> 标记图像的开始和结束。图片通过<u>视觉编码器</u>和<u>（位置级）视觉语言适配器</u>模块，得到一个定长的特征序列。为了和文字输入区别，图片特征前后分别加上 <code>&lt;img&gt;</code> 和 <code>&lt;/img&gt;</code>。</p>
<p>边界框输出：将边界框的值归一化在 <code>[0,1000)</code> 之间，并转换成特定的字符串格式 <code>&quot;(X_top_left, Y_top_left), (X_bottom_right, Y_bottom_right)&quot;</code> ，<code>&lt;box&gt;</code> 和 <code>&lt;/box&gt;</code> 分别添加在边界框字符串的开头和结尾。</p>
<p>内容输出：<code>&lt;ref&gt;</code> 和 <code>&lt;/ref&gt;</code> 标记边界框所引用的内容。</p>
<blockquote>
<p>例如，某个任务的提示词：</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs css">&lt;<span class="hljs-selector-tag">img</span>&gt;coyo700m/<span class="hljs-number">1</span><span class="hljs-selector-class">.jpg</span>&lt;/<span class="hljs-selector-tag">img</span>&gt;Generate the <span class="hljs-selector-tag">caption</span> in English with grounding:<br></code></pre></td></tr></table></figure>

<p>Qwen-VL 的回答如下：</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs apache"><span class="hljs-attribute">Beautiful</span> shot of &lt;ref&gt;bees&lt;/ref&gt;&lt;box&gt;(<span class="hljs-number">661</span>,<span class="hljs-number">612</span>),(<span class="hljs-number">833</span>,<span class="hljs-number">812</span>)&lt;/box&gt;&lt;box&gt;(<span class="hljs-number">120</span>,<span class="hljs-number">555</span>),(<span class="hljs-number">265</span>,<span class="hljs-number">770</span>)&lt;/box&gt; gathering nectars from &lt;ref&gt;an apricot flower&lt;/ref&gt;&lt;box&gt;(<span class="hljs-number">224</span>,<span class="hljs-number">13</span>),(<span class="hljs-number">399</span>,<span class="hljs-number">313</span>) &lt;/box&gt;&lt;eos&gt;<br></code></pre></td></tr></table></figure>
</blockquote>
<p>模型处理视觉信息的代码如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 确保只在第一次 forward 时处理视觉信息（past_key_values is None 表示不是缓存推理时）</span><br><span class="hljs-comment"># 图像 token 是以特殊的 image_start_id 开始，检测是否存在</span><br><span class="hljs-keyword">if</span> past_key_values <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span> <span class="hljs-keyword">and</span> torch.<span class="hljs-built_in">any</span>(input_ids == <span class="hljs-variable language_">self</span>.config.visual[<span class="hljs-string">&#x27;image_start_id&#x27;</span>]):<br>    <br>    	<span class="hljs-comment"># 找到图像 token 的边界位置</span><br>        bos_pos = torch.where(input_ids == <span class="hljs-variable language_">self</span>.config.visual[<span class="hljs-string">&#x27;image_start_id&#x27;</span>])<br>        eos_pos = torch.where(input_ids == <span class="hljs-variable language_">self</span>.config.visual[<span class="hljs-string">&#x27;image_start_id&#x27;</span>] + <span class="hljs-number">1</span>)<br>        <br>        <span class="hljs-comment"># 保证每个起始标记都在一个样本内部结束</span><br>        <span class="hljs-keyword">assert</span> (bos_pos[<span class="hljs-number">0</span>] == eos_pos[<span class="hljs-number">0</span>]).<span class="hljs-built_in">all</span>()<br>        <br>        <span class="hljs-comment"># 构建 img_pos：(batch_idx, start_idx, end_idx)</span><br>        img_pos = torch.stack((bos_pos[<span class="hljs-number">0</span>], bos_pos[<span class="hljs-number">1</span>], eos_pos[<span class="hljs-number">1</span>]), dim=<span class="hljs-number">1</span>)<br>        images = []<br>        <span class="hljs-keyword">for</span> i, a, b <span class="hljs-keyword">in</span> img_pos:<br>            <br>            <span class="hljs-comment"># 截取 patch token（跳过起始和终止标志）</span><br>            image = input_ids[i][a + <span class="hljs-number">1</span> : b - <span class="hljs-number">1</span>].tolist()<br>            <span class="hljs-comment"># 截取图片结束 token</span><br>            image = image[ : image.index(<span class="hljs-variable language_">self</span>.config.visual[<span class="hljs-string">&#x27;image_start_id&#x27;</span>] + <span class="hljs-number">2</span>)]<br>            <span class="hljs-comment"># 解码为 utf-8 图像数据（说明 image token 实际是原始图片字节的编码）</span><br>            images.append(<span class="hljs-built_in">bytes</span>(image).decode(<span class="hljs-string">&#x27;utf-8&#x27;</span>))<br>            <br>            <span class="hljs-comment"># 调用视觉编码器</span><br>            images = <span class="hljs-variable language_">self</span>.visual.encode(images)<br>            <span class="hljs-keyword">assert</span> images.shape[<span class="hljs-number">0</span>] == <span class="hljs-built_in">len</span>(images)<br>            <br>            fake_images = <span class="hljs-literal">None</span><br>            <span class="hljs-keyword">if</span> fake_images <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>                hidden_states = hidden_states + images.mean()*<span class="hljs-number">0</span><br>            <br>			<span class="hljs-comment"># 将图像嵌入写入对应位置 a+1 : b 的 hidden state（对应 patch tokens）</span><br>            <span class="hljs-keyword">elif</span> images <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>                <span class="hljs-keyword">for</span> idx, (i, a, b) <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(img_pos):<br>                    hidden_states[i][a + <span class="hljs-number">1</span> : b] = images[idx]<br></code></pre></td></tr></table></figure>

<blockquote>
<p>Q：<code>image = image[ : image.index(self.config.visual[&#39;image_start_id&#39;] + 2)]</code> 这段代码的作用？</p>
<p>A：因为模型在输入图片时，有时会预留更多 token 空间来填充图像信息，例如 padding 和 filter ，这就导致图像本身可能变长。这些填充的 token 确实是图像的一部分，但是输入到视觉编码器中产生干扰，因此需要额外再加一行代码对这些填充 token 做进一步过滤。</p>
</blockquote>
<h2 id="模型训练过程"><a href="#模型训练过程" class="headerlink" title="模型训练过程"></a>模型训练过程</h2><h3 id="第一阶段：预训练过程"><a href="#第一阶段：预训练过程" class="headerlink" title="第一阶段：预训练过程"></a>第一阶段：预训练过程</h3><p>使用互联网网页抓取的 ”图像—文本“ 对，50 亿条数据清洗后剩下 14 亿数据，其中 77.3% 为英文数据，22.7% 为中文数据。<b>这一阶段冻结语言模型</b>，训练视觉编码器和视觉语言适配器，输入图像调整为 224x224 的分辨率（按照每 14 像素分割后得到 16x16&#x3D;256 个 patch），batch size 为 30720 ，训练 50000 步，使用 15 亿数据。</p>
<h3 id="第二阶段：多任务预训练"><a href="#第二阶段：多任务预训练" class="headerlink" title="第二阶段：多任务预训练"></a>第二阶段：多任务预训练</h3><p>加入了高质量、细粒度的图像和文本数据，使用了更大的分辨率和交错的 ”图像—文本“ 数据。在 7 个任务上对 Qwen-VL 进行训练。将视觉编码器的分辨率从 224x224 增加到 448x448，以减少图像下采样造成的信息损失。<b>这一过程没有冻结任何模块。</b></p>
<h3 id="第三阶段：监督微调"><a href="#第三阶段：监督微调" class="headerlink" title="第三阶段：监督微调"></a>第三阶段：监督微调</h3><p>数据<u>来自 LLM 生成</u>的图像标注或对话数据，这些数据通常只处理<b>单图像对话和推理</b>，且仅限于图像内容理解。</p>
<p>通过<u>手动标注、模型生成和策略组合</u>，构建了一个额外的对话数据集，以将<b>定位和多图像理解能力</b>融入 Qwen-VL 模型中。在训练过程中混合了多模态和<u>纯文本对话数据</u>，以确保模型的对话能力具有普遍性。</p>
<p>指令微调数据量达到 35 万条。<b>这一过程冻结视觉编码器。</b></p>
<h2 id="模型代码应用"><a href="#模型代码应用" class="headerlink" title="模型代码应用"></a>模型代码应用</h2><h3 id="图片和文本的加载"><a href="#图片和文本的加载" class="headerlink" title="图片和文本的加载"></a>图片和文本的加载</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">query = tokenizer.from_list_format([<br>    &#123;<span class="hljs-string">&#x27;image&#x27;</span>: <span class="hljs-string">&#x27;https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-VL/assets/demo.jpeg&#x27;</span>&#125;,<br>    &#123;<span class="hljs-string">&#x27;text&#x27;</span>: <span class="hljs-string">&#x27;这是什么&#x27;</span>&#125;,<br>])<br></code></pre></td></tr></table></figure>

<h3 id="图像到字符串的转换"><a href="#图像到字符串的转换" class="headerlink" title="图像到字符串的转换"></a>图像到字符串的转换</h3><p>Qwen-VL 将图片都处理成：“Picture 1”、“Picture 2”、“Picture 3” 等<u>字符串</u>格式，并添加上<u>图片的开始和结束 token</u> ，文本直接拼接，box 的 <u>ref 添加上开始结束符</u>拼接，box <u>坐标从数字整理成字符串格式</u>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs PYTHON"><span class="hljs-keyword">def</span> <span class="hljs-title function_">from_list_format</span>(<span class="hljs-params">self, list_format: <span class="hljs-type">List</span>[<span class="hljs-type">Dict</span>]</span>):<br>    text = <span class="hljs-string">&#x27;&#x27;</span><br>    num_images = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> ele <span class="hljs-keyword">in</span> list_format:  <span class="hljs-comment"># 每个 ele 都是字典</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;image&#x27;</span> <span class="hljs-keyword">in</span> ele:<br>            <span class="hljs-comment"># 图片处理成这样的字符串，再加上图像自身、开始和结束的 tokens</span><br>            num_images += <span class="hljs-number">1</span><br>            text += <span class="hljs-string">f&#x27;Picture <span class="hljs-subst">&#123;num_images&#125;</span>: &#x27;</span><br>            text += <span class="hljs-variable language_">self</span>.image_start_tag + ele[<span class="hljs-string">&#x27;image&#x27;</span>] + <span class="hljs-variable language_">self</span>.image_end_tag<br>            text += <span class="hljs-string">&#x27;\n&#x27;</span><br>            <br>        <span class="hljs-keyword">elif</span> <span class="hljs-string">&#x27;text&#x27;</span> <span class="hljs-keyword">in</span> ele:<br>            <span class="hljs-comment"># 如果是文本，直接添加文本</span><br>            text += ele[<span class="hljs-string">&#x27;text&#x27;</span>]<br>            <br>        <span class="hljs-keyword">elif</span> <span class="hljs-string">&#x27;box&#x27;</span> <span class="hljs-keyword">in</span> ele:<br>            <span class="hljs-comment"># 如果是定位框，先考虑有没有参考对象</span><br>            <span class="hljs-comment"># 如果有的话，先添加参考对象自身字符串、开始和结束的 tokens</span><br>            <span class="hljs-comment"># 没有的话，添加定位框自身字符串、开始和结束的 tokens</span><br>            <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;ref&#x27;</span> <span class="hljs-keyword">in</span> ele:<br>                text += <span class="hljs-variable language_">self</span>.ref_start_tag + ele[<span class="hljs-string">&#x27;ref&#x27;</span>] + <span class="hljs-variable language_">self</span>.ref_end_tag<br>            <span class="hljs-keyword">for</span> box <span class="hljs-keyword">in</span> ele[<span class="hljs-string">&#x27;box&#x27;</span>]:<br>                text += <span class="hljs-variable language_">self</span>.box_start_tag + <span class="hljs-string">&#x27;(%d,%d),(%d,%d)&#x27;</span> % (box[<span class="hljs-number">0</span>], box[<span class="hljs-number">1</span>], box[<span class="hljs-number">2</span>], box[<span class="hljs-number">3</span>]) + <span class="hljs-variable language_">self</span>.box_end_tag<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&quot;Unsupport element: &quot;</span> + <span class="hljs-built_in">str</span>(ele))<br>    <span class="hljs-keyword">return</span> text<br></code></pre></td></tr></table></figure>

<h3 id="图像的编码"><a href="#图像的编码" class="headerlink" title="图像的编码"></a>图像的编码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">encode</span>(<span class="hljs-params">self, image_paths: <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>]</span>):<br>        images = []<br>        <span class="hljs-keyword">for</span> image_path <span class="hljs-keyword">in</span> image_paths:<br>            <span class="hljs-keyword">if</span> image_path.startswith(<span class="hljs-string">&quot;http://&quot;</span>) <span class="hljs-keyword">or</span> image_path.startswith(<span class="hljs-string">&quot;https://&quot;</span>):<br>                image = Image.<span class="hljs-built_in">open</span>(requests.get(image_path, stream=<span class="hljs-literal">True</span>).raw)<br>            <span class="hljs-keyword">else</span>:<br>                image = Image.<span class="hljs-built_in">open</span>(image_path)<br>            image = image.convert(<span class="hljs-string">&quot;RGB&quot;</span>)<br>            images.append(<span class="hljs-variable language_">self</span>.image_transform(image))<br>        images = torch.stack(images, dim=<span class="hljs-number">0</span>)<br>        <span class="hljs-keyword">return</span> <span class="hljs-variable language_">self</span>(images)<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x: torch.Tensor</span>):<br>        x = x.to(<br>            dtype=<span class="hljs-variable language_">self</span>.transformer.get_cast_dtype(),<br>            device=<span class="hljs-variable language_">self</span>.transformer.get_cast_device(),<br>        )<br>        <span class="hljs-comment"># to patches</span><br>        x = <span class="hljs-variable language_">self</span>.conv1(x)  <span class="hljs-comment"># shape = [*, width, grid, grid]</span><br>        x = x.reshape(x.shape[<span class="hljs-number">0</span>], x.shape[<span class="hljs-number">1</span>], -<span class="hljs-number">1</span>)  <span class="hljs-comment"># shape = [*, width, grid ** 2]</span><br>        x = x.permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>)  <span class="hljs-comment"># shape = [*, grid ** 2, width]</span><br><br>        x = x + get_abs_pos(<span class="hljs-variable language_">self</span>.positional_embedding, x.size(<span class="hljs-number">1</span>))<br><br>        x = <span class="hljs-variable language_">self</span>.ln_pre(x)<br><br>        x = x.permute(<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>)  <span class="hljs-comment"># NLD -&gt; LND</span><br>        x = <span class="hljs-variable language_">self</span>.transformer(x)<br>        x = x.permute(<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>)  <span class="hljs-comment"># LND -&gt; NLD</span><br><br>        x = <span class="hljs-variable language_">self</span>.attn_pool(x)<br>        x = <span class="hljs-variable language_">self</span>.ln_post(x)<br>        x = x @ <span class="hljs-variable language_">self</span>.proj<br></code></pre></td></tr></table></figure>

<p>图片是经过 resize 和归一化后输入 ViT 进行编码，ViT 编码后经过交叉注意力机制、归一化然后投影到 embedding 维度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-variable language_">self</span>.attn_pool = Resampler(<br>            grid_size=<span class="hljs-built_in">int</span>(math.sqrt(n_queries)),<br>            embed_dim=output_dim,<br>            num_heads=output_dim // <span class="hljs-number">128</span>,<br>            kv_dim=width,<br>            norm_layer=norm_layer,<br>        )<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x, attn_mask=<span class="hljs-literal">None</span></span>):<br><br>        pos_embed = get_abs_pos(<span class="hljs-variable language_">self</span>.pos_embed, x.size(<span class="hljs-number">1</span>))<br><br>        x = <span class="hljs-variable language_">self</span>.kv_proj(x)<br>        x = <span class="hljs-variable language_">self</span>.ln_kv(x).permute(<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>)<br><br>        N = x.shape[<span class="hljs-number">1</span>]<br>        q = <span class="hljs-variable language_">self</span>.ln_q(<span class="hljs-variable language_">self</span>.query)<br>        out = <span class="hljs-variable language_">self</span>.attn(<br>            <span class="hljs-variable language_">self</span>._repeat(q, N) + <span class="hljs-variable language_">self</span>.pos_embed.unsqueeze(<span class="hljs-number">1</span>),<br>            x + pos_embed.unsqueeze(<span class="hljs-number">1</span>),<br>            x,<br>            attn_mask=attn_mask)[<span class="hljs-number">0</span>]<br>        <span class="hljs-keyword">return</span> out.permute(<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>)<br></code></pre></td></tr></table></figure>




                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B/" class="print-no-link">#多模态大模型</a>
      
        <a href="/tags/Qwen-VL/" class="print-no-link">#Qwen-VL</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>QwenVL系列多模态模型学习笔记_第1篇</div>
      <div>http://example.com/2025/06/25/QwenVL系列多模态模型学习笔记-第1篇/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Jinbiao Zhu</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年6月25日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2025/06/25/QwenVL%E7%B3%BB%E5%88%97%E5%A4%9A%E6%A8%A1%E6%80%81%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%AC%AC2%E7%AF%87/" title="QwenVL系列多模态模型学习笔记-第2篇">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">QwenVL系列多模态模型学习笔记-第2篇</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>





  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
