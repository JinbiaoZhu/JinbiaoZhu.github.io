

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="Jinbiao Zhu">
  <meta name="keywords" content="">
  
    <meta name="description" content="第二代 Qwen2-VL 2024.09-2024.10 引入原生动态分辨率（Naive Dynamic Resolution, NDR）机制 —— 实现了对任意分辨率图像&#x2F;视频的灵活处理。 设计多模态旋转位置嵌入（Multimodal Rotary Position Embedding, M-RoPE） —— 提升了模型的跨模态理解能力，还增强了长序列任务中的推理表现，在视频内容理解中">
<meta property="og:type" content="article">
<meta property="og:title" content="QwenVL系列多模态模型学习笔记-第2篇">
<meta property="og:url" content="http://example.com/2025/06/25/QwenVL%E7%B3%BB%E5%88%97%E5%A4%9A%E6%A8%A1%E6%80%81%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%AC%AC2%E7%AF%87/index.html">
<meta property="og:site_name" content="JinbiaoZhu">
<meta property="og:description" content="第二代 Qwen2-VL 2024.09-2024.10 引入原生动态分辨率（Naive Dynamic Resolution, NDR）机制 —— 实现了对任意分辨率图像&#x2F;视频的灵活处理。 设计多模态旋转位置嵌入（Multimodal Rotary Position Embedding, M-RoPE） —— 提升了模型的跨模态理解能力，还增强了长序列任务中的推理表现，在视频内容理解中">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/2025/06/25/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AF%84%E6%B5%8B%E4%BD%93%E7%B3%BBMMBench%E5%AD%A6%E4%B9%A0%E4%B8%8E%E4%BD%BF%E7%94%A8/wen2_vl_frame.jpg">
<meta property="article:published_time" content="2025-06-25T12:45:18.000Z">
<meta property="article:modified_time" content="2025-06-25T14:20:17.885Z">
<meta property="article:author" content="Jinbiao Zhu">
<meta property="article:tag" content="多模态大模型">
<meta property="article:tag" content="Qwen-VL">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://example.com/2025/06/25/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AF%84%E6%B5%8B%E4%BD%93%E7%B3%BBMMBench%E5%AD%A6%E4%B9%A0%E4%B8%8E%E4%BD%BF%E7%94%A8/wen2_vl_frame.jpg">
  
  
  
  <title>QwenVL系列多模态模型学习笔记-第2篇 - JinbiaoZhu</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.8","typing":{"enable":false,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>JinbiaoZhu</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle">QwenVL系列多模态模型学习笔记-第2篇</span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-06-25 20:45" pubdate>
          2025年6月25日 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          2.3k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          20 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">QwenVL系列多模态模型学习笔记-第2篇</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="第二代-Qwen2-VL-2024-09-2024-10"><a href="#第二代-Qwen2-VL-2024-09-2024-10" class="headerlink" title="第二代 Qwen2-VL 2024.09-2024.10"></a>第二代 Qwen2-VL 2024.09-2024.10</h1><ul>
<li>引入<b>原生动态分辨率（Naive Dynamic Resolution, NDR）</b>机制 —— 实现了对<u>任意分辨率图像&#x2F;视频</u>的灵活处理。</li>
<li>设计<b>多模态旋转位置嵌入（Multimodal Rotary Position Embedding, M-RoPE）</b> —— 提升了模型的跨模态理解能力，还增强了长序列任务中的推理表现，在视频内容理解中尤为突出。</li>
<li>更强的复杂推理和决策的能力，可根据视觉环境和文字指令进行自动操作手机、机器人等设备。</li>
<li>支持除英语和中文外，也支持大多数欧洲语言、日语、韩语、阿拉伯语、越南语等<b>多语言</b>。</li>
<li>统一的多模态学习框架 —— 确保模型对多模态任务的全面适配。</li>
<li>显著性能提升 —— 在多个权威基准数据集上实现了新 SoTA 。</li>
</ul>
<h2 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h2><blockquote>
<p>通常一个多模态 “视觉—语言” 模型包含三个结构：语言模型、视觉编码器和 “视觉—语言” 适配器。</p>
</blockquote>
<p><img src="/2025/06/25/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AF%84%E6%B5%8B%E4%BD%93%E7%B3%BBMMBench%E5%AD%A6%E4%B9%A0%E4%B8%8E%E4%BD%BF%E7%94%A8/wen2_vl_frame.jpg" srcset="/img/loading.gif" lazyload></p>
<ul>
<li><p>视觉编码器</p>
<p>图像和视频帧经过基于 ViT 的视觉编码器后，生成一系列视觉特征 token 。取代传统绝对位置编码，模型通过二维 RoPE 嵌入捕捉图像中<b>像素空间分布</b>信息。为了降低计算复杂度，视觉特征通过<u>一个简单的 MLP 层</u>进一步压缩，将邻近的 2x2 视觉 token 合并为一个 token ，同时在 token 序列的起始和结尾处分别添加<code>&lt;|vision_start|&gt;</code> 和 <code>&lt;|vision_end|&gt;</code> 标记。</p>
</li>
<li><p>语言模型</p>
<p>使用 Qwen2-LM ，Qwen2 系列语言模型都是基于 Transformer 的解码器结构。视觉特征 tokens 和文本 tokens 通过统一的输入序列被送入 Qwen2 系列语言模型中，进行多模态信息的融合和处理。</p>
</li>
<li><p>多模态旋转位置嵌入（M-RoPE）</p>
<p>M-RoPE 在视觉和文本 token 之间建立精确的位置信息关联。特别是在视频任务中， M-RoPE 能够捕捉时间维度的动态变化，使模型能够处理长时间的视频内容。</p>
<p>对于文本，位置编码与传统的 1D-RoPE 一致，采用<u>一维序列编号</u>来标记词位位置。</p>
<p>对于图像，M-RoPE 通过<u>二维位置编码</u>为每个视觉 token 分配宽度和高度的位置标识，以准确表示图像中的空间结构。同时，图像中的时间维度编码值保持固定，因为静态图像没有时间变化。</p>
<p>对于视频，M-RoPE 进一步扩展，通过对<b>每一帧引入递增的时间位置标识</b>，并结合图像的宽度和高度位置编码，使模型能够理解视频帧的动态时间序列信息。</p>
</li>
</ul>
<h2 id="模型输入和输出"><a href="#模型输入和输出" class="headerlink" title="模型输入和输出"></a>模型输入和输出</h2><p>图像输入：模型根据输入图像的分辨率，动态调整视觉 token 的数量，而不是将所有图像固定调整到同一尺寸。</p>
<p>视频输入：对于视频数据，为了一致性，每个图像被视为两个相同的帧。为了平衡长视频处理的计算需求和整体训练效率，动态调整每个视频帧的分辨率，将每个视频的令牌总数限制在 16384 个，并利用动态分辨率机制压缩多帧内容为适合语言模型处理的视觉 token 序列。</p>
<p>模型输出：</p>
<ul>
<li>视觉问答（VQA）：回答与图像或视频相关的问题。</li>
<li>文档理解与 OCR ：识别和解析复杂文档中的文本信息。</li>
<li>视频内容分析：对长视频内容进行总结、生成对话内容或回答基于视频的问题。</li>
<li>代理能力：支持设备操作，如根据屏幕截图导航手机界面。</li>
</ul>
<h2 id="模型训练过程"><a href="#模型训练过程" class="headerlink" title="模型训练过程"></a>模型训练过程</h2><h3 id="第一阶段：ViT-训练，冻结语言模型参数"><a href="#第一阶段：ViT-训练，冻结语言模型参数" class="headerlink" title="第一阶段：ViT 训练，冻结语言模型参数"></a>第一阶段：ViT 训练，冻结语言模型参数</h3><p>使用大量的 “图像—文本” 对数据集来增强大语言模型（LLM）中的语义理解，让模型学会图像和文本之间的关系，以及通过 OCR 在图像中识别文本内容和图像分类任务。</p>
<p>在这一阶段，Qwen2-VL 大约使用 6000 亿个标记的语料库预训练。LLM 部分使用 Qwen2 的参数进行初始化，而 ViT 部分则使用<u>从 DFN 派生的 ViT</u> 进行初始化。</p>
<blockquote>
<p>DFN 即 <strong>Data Filtering Network</strong>，是一个<strong>小型的、专门用于 “筛数据” 的神经网络</strong>。它通常会接收<strong>图像—文本对</strong>，并预测其质量评分，高分样本被保留用于训练大型预训练模型。它本身不直接生成训练模型，而是在 “构建训练集” 的中间环节发挥作用。</p>
</blockquote>
<h3 id="第二阶段：解冻-ViT-和语言模型进行全参数训练"><a href="#第二阶段：解冻-ViT-和语言模型进行全参数训练" class="headerlink" title="第二阶段：解冻 ViT 和语言模型进行全参数训练"></a>第二阶段：解冻 ViT 和语言模型进行全参数训练</h3><p>解冻所有参数，并使用更广泛的数据进行训练，以实现更全面的学习。这个阶段引入了额外的 8000 亿个图像相关数据的标记，通过引入更多的混合 “图像—文本” 内容，以促进视觉和文本信息之间更细微的理解。</p>
<h3 id="第三阶段：LLM-的微调"><a href="#第三阶段：LLM-的微调" class="headerlink" title="第三阶段：LLM 的微调"></a>第三阶段：LLM 的微调</h3><p>使用 ChatML 格式构建指令跟随数据。冻结 ViT 参数，使用指令数据集对 LLM 进行专门的微调。</p>
<h3 id="训练手段"><a href="#训练手段" class="headerlink" title="训练手段"></a>训练手段</h3><ol>
<li>数据预处理（data preprocessing）：先将不同分辨率图片进行 patch 处理</li>
<li>连续型词元丢弃（continuous token dropping）：过去，Token Dropout 也就是<b>训练过程中随机省略输入 patch </b>，是以固定比例进行的，这在处理<u>相同分辨率的图像</u>时效果良好。但在支持任意分辨率的情况下，需要根据图像的大小来动态调整 Token Dropout 的比例。简单来说，大小为 10x30 的图像不能与 100x300 的图像使用相同的丢弃比例。通过根据图像尺寸进行调整，可以确保不同分辨率下的训练效果最佳</li>
<li>分辨率采样。在传统的 ViT 模型中，训练时存在性能与效率的权衡：较小分辨率的图像能<u>提高训练效率</u>，而较大分辨率的图像<u>有助于提高模型在评估阶段的表现</u>。因此，模型通常会先在较低分辨率下预训练，然后再在较高分辨率下进行微调。相比之下，NaViT 具有更大的灵活性，它通过从不同的图像尺寸中进行采样，支持混合分辨率训练，并保持每张图像的原始纵横比。这种方法不仅提高了训练效率，还能让模型接触到更大分辨率的图像，从而在相同模型大小和训练时长下，显著提升性能。</li>
</ol>
<h2 id="模型代码应用"><a href="#模型代码应用" class="headerlink" title="模型代码应用"></a>模型代码应用</h2><h2 id="引申：从-Pix2Struct-到-NaViT-到-NDR"><a href="#引申：从-Pix2Struct-到-NaViT-到-NDR" class="headerlink" title="引申：从 Pix2Struct 到 NaViT 到 NDR"></a>引申：从 Pix2Struct 到 NaViT 到 NDR</h2><p>NDR 这一方法的引入来自 2024 年 NIPS 的一个工作：NaViT。</p>
<p>原生 ViT 对图片的处理是先将图片 resize 到固定尺寸，然后分为 nxn 个 patch，每个 patch 得到 patch embedding，再输入 transformer 层中。但这种情况下对于非固定尺寸的照片会扭曲其内容。</p>
<p>Pix2Struct 针对 ViT 需要 resize 到固定尺寸的缺点，提出了一种方法保持长宽比率的缩放，并且为此构建了一个可学习的二维位置编码：<code>max_seq * max_seq * embed_dim</code> 的矩阵，Pix2Struct 引入了可学习的二维绝对位置编码。这些编码的尺寸为 <code>[maxLen, maxLen]</code> ，并且通过每个 patch 的  (x, y)  坐标进行索引。这意味着模型能够根据图像中的坐标来学习特定的空间位置信息，从而在面对不同的图像比例时表现得更加灵活和精准。它允许模型处理的图像分辨率最高可以达到 <code>R = P·maxLen</code> ， P 表示 patch 的数量，maxLen 代表最大长度。然而，这种方法也有其局限性，那就是训练过程中必须看到所有可能的 <code>(x, y)</code> 坐标组合，才能让模型充分学习到位置信息。</p>
<p>NaViT 对此进行了以下做法：</p>
<ol>
<li><p>模型层面：</p>
<p>Masked Self-Attention。NaViT 模型引入了 Masked Self-Attention 机制，确保在进行自注意力计算时，每个图像只能关注到自身内容，而不会与其他图像发生交互；</p>
<p>Masked Pooling：每张图片上各自去进行 pooling ，独立的进行信息聚合，而不是全局聚合，有助于保留图像的局部特征；</p>
</li>
<li><p>位置编码：为了支持可变的长宽比并能够将位置编码扩展到未见过的分辨率，研究者提出了因子化的位置编码方法， 将位置编码分解为 x 和 y 坐标的独立编码 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϕ</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\phi(x) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">ϕ</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span></span></span></span> 和 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϕ</mi><mo stretchy="false">(</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\phi(y) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">ϕ</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span> ，最后将它们相加。</p>
<p>在此基础上，提出了两种编码方案：</p>
<p>（1）绝对位置编码：其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϕ</mi><mo stretchy="false">(</mo><mi>p</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\phi(p) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">ϕ</span><span class="mopen">(</span><span class="mord mathnormal">p</span><span class="mclose">)</span></span></span></span> 是根据 patch 的绝对位置索引的函数，即位置编码是基于图像中的绝对坐标进行计算的；</p>
<p>（2）分数位置编码：其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ϕ</mi><mo stretchy="false">(</mo><mi>r</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\phi(r) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">ϕ</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mclose">)</span></span></span></span> 是相对距离的函数，即相对于 patch 边长的距离，这种编码独立于图像尺寸，从而部分模糊了图像的原始长宽比，优势在于它能够提供独立于图像尺寸的位置编码参数，但也因此部分掩盖了原始长宽比的信息，仅在 patch 数量中隐含地体现了这一信息。</p>
</li>
</ol>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B/" class="print-no-link">#多模态大模型</a>
      
        <a href="/tags/Qwen-VL/" class="print-no-link">#Qwen-VL</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>QwenVL系列多模态模型学习笔记-第2篇</div>
      <div>http://example.com/2025/06/25/QwenVL系列多模态模型学习笔记-第2篇/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>Jinbiao Zhu</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年6月25日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2025/06/25/QwenVL%E7%B3%BB%E5%88%97%E5%A4%9A%E6%A8%A1%E6%80%81%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%AC%AC1%E7%AF%87/" title="QwenVL系列多模态模型学习笔记_第1篇">
                        <span class="hidden-mobile">QwenVL系列多模态模型学习笔记_第1篇</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>





  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
